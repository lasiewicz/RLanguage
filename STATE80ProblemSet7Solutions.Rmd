---
title: "Problem Set 7"
subtitle: 'STAT E-80: Basic Probability Using R'
output:
  html_document:
    df_print: paged
  pdf_document: default
---


# Problem 1


A certain disease occurs in 1.5\% of the population. A diagnostic test for this disease has sensitivity 90\% and specificity 85\%.

###Part (a)

What is the probability of a false positive with this test?

**Answer** The probability of a false positive is defined as the conditional probability of a positive test result, given that the patient does not have the disease, and this is denoted as $\Pr(T^+\ |\ D^-)$. We can use the complement trick for conditional probabilities to calculate this:
$$
\Pr(T^+\ |\ D^-)\ =\ 1 - \Pr( (T^+)^c\ |\ D^-)
$$
But the complement of a positive test, denoted $(T^+)^c$, is just $T^-$. Thus, the complement trick is:
$$
\Pr(T^+\ |\ D^-)\ =\ 1 - \Pr( T^-\ |\ D^-)
$$
But the term $\Pr(T^-\ |\ D^-)$ is the probability of a negative test result, given that the patient does not have the disease. By definition this is the specificity of the test, and we know from the problem statement that this is 0.85. Thus, the probability of a false positive is 1 - 0.85 = 0.15.




###Part (b)

What is the probability of a false negative for this test?

**Answer** The probability of a false negative is defined as the conditional probability of a negative test result, given that the patient has the disease, and this is denoted as $\Pr(T^-\ |\ D^+)$. We can use the complement trick for conditional probabilities to calculate this:
$$
\Pr(T^-\ |\ D^+)\ =\ 1 - \Pr( (T^-)^c\ |\ D^+)
$$
But the complement of a negative test, denoted $(T^-)^c$, is just $T^+$. Thus, the complement trick becomes:
$$
\Pr(T^-\ |\ D^+)\ =\ 1 - \Pr( T^+\ |\ D^+)
$$
The term $\Pr(T^+\ |\ D^+)$ is the probability of a positive test result, given that the patient has the disease. By definition this is the sensitivity of the test, and we know from the problem statement that this is 0.90. Thus, the probability of a false positive is 1 - 0.90 = 0.10.



###Part (c)

Using Bayes' theorem, calculate the positive predictive value for this test.

**Answer**
It's a good idea to define variables to hold the values of the sensitivity, specificity, and prevalence, and then to work with these with the formula for the positive predictive value:
```{r}
sensitivity <- 0.90
specificity <- 0.85
prevalence <- 0.015

(sensitivity * prevalence) / ( (sensitivity * prevalence) + ( (1 - specificity) * (1 - prevalence) ) )
```
The positive predictive value of the test is 8.4\%.



###Part (d)

Construct a simulation to verify that your answer in part (c) is correct. You are welcome to borrow the code from the Lecture 8 R notebook and modify it.

**Answer**

```{r}
number.replications <- 100000

# We specify the sensitivity, specificity, and prevalence just once,
# and then use these variables in the code. That way, if we want to
# use different values, it's easy to make the changes.

sensitivity <- 0.90
specificity <- 0.85
prevalence <- 0.015

# We need two result vectors, one for disease status,
# and the other for the test result.

disease.vector <- character( number.replications )
test.vector <- character( number.replications )

for( replication.index in 1:number.replications ) {
    
    # First, we simulate the disease status
    
    disease.status <- sample( c("Diseased", "Healthy"), 1,
                              prob = c(prevalence, 1-prevalence) )
    
    # Now we simulate the test result; this will depend on
    # the disease status of the patient
    
    if( disease.status == "Diseased" ) {
        
        # For a subject with disease, we use the sensitivity
        # to randomly sample the test result
        
        test.result <- sample( c("Positive", "Negative"), 1,
                               prob = c(sensitivity, 1 - sensitivity) )
        
    } else {
        
        # For a subject without disease, we use the specificity
        # to randomly sample the test result
        
        test.result <- sample( c("Positive", "Negative"), 1,
                               prob = c(1-specificity, specificity) )
    }
    
    # Now that we have the disease status and the test result,
    # let's store these in the result vectors:
    
    disease.vector[ replication.index ] <- disease.status
    test.vector[ replication.index ] <- test.result
}

# Finally, we use our standard 
filtered.vector <- disease.vector[ test.vector == "Positive" ]
mean( filtered.vector == "Diseased" )



```
This value should be close to 8.3\%.


\newpage
# Problem 2

Justin uses hashtags in 70\% of his text messages, while Caitlin uses hashtags in 35\% of her messages. Caitlin sends 55\% of the text messages between the two, while Justin sends 45\% of the messages. Now you observe the message:

*yo wassup wuz u @ that crazee partee?!? lol*

### Part (a)

Using Bayes' theorem, calculate the conditional probability that Caitlin sent the message.

**Answer** The important point to note about this problem is that this text message does not contain a hashtag. So we are dealing with the opposite situation from lecture. Let's write out Bayes' Theorem, changing the letters to reflect Justin and Caitlin:
$$
\Pr(C\ |\ H^-)\ =\  \frac{ \Pr(H^-\ |\ C) \cdot \Pr(C) }{ (\Pr(H^-\ |\ C) \cdot \Pr(C)) + (\Pr(H^-\ |\ J) \cdot \Pr(J))}
$$
Now we have to calculate these conditional probabilities using the information from the problem statement. First, we can use the complement trick for conditional probabilities to determine the probability that Caitlin will send a text message without a hashtag:
    \begin{eqnarray*}
        \Pr(H^-\ |\ C) & = & 1 - \Pr( (H^-)^c\ |\ C)\\
        \\
        & = & 1 - \Pr(H\ |\ C)\\
        \\
        & = & 1 - 0.35\\
        \\
        & = & 0.65
    \end{eqnarray*}

Likewise, to determine $\Pr(H^-\ |\ J)$, the conditional probability that Justin will send a text message without a hashtag, we do essentially the same calculation:
    \begin{eqnarray*}
        \Pr(H^-\ |\ J) & = & 1 - \Pr( (H^-)^c\ |\ J)\\
        \\
        & = & 1 - \Pr(H\ |\ J)\\
        \\
        & = & 1 - 0.70\\
        \\
        & = & 0.30
    \end{eqnarray*}

Finally, from the problem statement, we have:
    \begin{eqnarray*}
        \Pr(C) & = & 0.55\\
        \\
        \Pr(J) & = & 0.45
    \end{eqnarray*}
    
Now let's use R to calculate the conditional probability that Caitlin sent the message, given that there is no hashtag:
```{r}
prob.no.hashtag.caitlin <- 0.65
prob.no.hashtag.justin <- 0.30
prob.caitlin <- 0.55
prob.justin <- 0.45

(prob.no.hashtag.caitlin * prob.caitlin) /
    ( (prob.no.hashtag.caitlin * prob.caitlin) + (prob.no.hashtag.justin * prob.justin) )
```








###Part (b)

Construct a simulation to show that your calculation in part (a) is correct.

**Answer**

```{r}
number.replications <- 100000

prob.hashtag.justin <- 0.70
prob.hashtag.caitlin <- 0.35
prob.caitlin <- 0.55

# We need two result vectors, one to keep track of
# the sender of the message, and the other to keep track
# of the presence or absence of a hashtag.

sender.vector <- character( number.replications )
hashtag.vector <- character( number.replications )

# The sender of the message in this problem is analogous
# to the disease status in the screening problem, while
# the hashtag is analogous to the diagnostic test.

for( replication.index in 1:number.replications ) {
    
    # First, we randomly generate the sender of the message
    
    sender <- sample( c("Caitlin", "Justin"), 1,
                              prob = c(prob.caitlin, 1-prob.caitlin) )
    
    # Next, we randomly generate the presence or absence of a hashtag, given
    # that the sender
    
    if( sender == "Caitlin" ) {
        hashtag.status <- sample( c("Yes", "No"), 1,
                               prob = c(prob.hashtag.caitlin, 1 - prob.hashtag.caitlin) )
    } else {
        hashtag.status <- sample( c("Yes", "No"), 1,
                               prob = c(prob.hashtag.justin, 1-prob.hashtag.justin) )
    }
    
    # Now we store the sender and hashtag.status in result vectors:
    
    sender.vector[ replication.index ] <- sender
    hashtag.vector[ replication.index ] <- hashtag.status
    
}

# Finally, we use standard filtering method. First, we extract those
# elements of the sender vector that had a hashtag in their email.

filtered.vector <- sender.vector[ hashtag.vector == "No" ]

# Next, we determine the proportion of the filtered values
# that were really sent by Caitlin

mean( filtered.vector == "Caitlin" )
```
This value should be close to 0.726.


\newpage
# Problem 3

An insurance company finds that 85\% of the policyholders are good drivers, and 15\% of the policyholders are bad drivers. A good driver has a 10\% probability of having a car accident in one year, while a bad driver has a 35\% probability of having a car accident in one year.

### Part (a)

The Chevalier de Mere had an accident last year. Use Bayes' theorem to calculate the probability that he is a bad driver.

**Answer** Let's use some notation that is suited to the problem:

* The letter $A$ denotes the event that an accident occurred in one year.

* The letter $G$ denotes the event that the Chevalier is a good driver.

* The letter $B$ denotes the event that the Chevalier is a bad driver.

In this problem there are only good drivers or bad drivers, so if a driver is not a bad driver then he or she must be a good driver i.e.\ we must have $G = B^c$. Now Bayes' theorem has the form:
$$
\Pr(B\ |\ A)\ =\ \frac{ \Pr(A\ |\ B) \cdot \Pr(B)}{ \Pr(A\ |\ B) \cdot \Pr(B)\ +\ \Pr(A\ |\ G) \cdot \Pr(G)}
$$

Now let's substitute in the values specified in the problem statement:
\begin{eqnarray*}
    \Pr(B\ |\ A) & = & \frac{ \Pr(A\ |\ B) \cdot \Pr(B)}{ \Pr(A\ |\ B) \cdot \Pr(B)\ +\ \Pr(A\ |\ G) \cdot \Pr(G)}\\
    \\
    & = & \frac{ 0.35 \times 0.15 }{ (0.35 \times 0.15) + (0.10 \times 0.85)}\\
    \\
    & = & \frac{ 0.0525 }{ 0.0525 + 0.0850}\\
    \\
    & = & 0.38182
\end{eqnarray*}
Let's do this in R:
```{r}
prob.accident.good.driver <- 0.10
prob.accident.bad.driver <- 0.35
prob.good.driver <- 0.85
prob.bad.driver <- 0.15

(prob.accident.bad.driver * prob.bad.driver) / ( (prob.accident.bad.driver * prob.bad.driver) + (prob.accident.good.driver * prob.good.driver))
```







### Part (b)

Construct a simulation to show that your calculation in part (a) is correct.

**Answer**

```{r}
number.replications <- 100000

prob.accident.good.driver <- 0.10
prob.accident.bad.driver <- 0.35
prob.good.driver <- 0.85
prob.bad.driver <- 0.15


# We need two result vectors, one to keep track of
# whether the driver is good or bad, and the other to keep track
# of whether the driver had an accident.

driver.vector <- character( number.replications )
accident.vector <- character( number.replications )

# The driver status of good or bad in this problem is analogous
# to the disease status in the screening problem, while
# having an accident is analogous to the diagnostic test.

for( replication.index in 1:number.replications ) {
    
    # First, we randomly generate the driver status
    
    driver.status <- sample( c("Good Driver", "Bad Driver"), 1,
                              prob = c(prob.good.driver, prob.bad.driver) )
    
    # Next, we randomly generate whether the driver had an accident, given
    # the status of the driver
    
    if( driver.status == "Good Driver" ) {
        accident.status <- sample( c("Accident", "No Accident"), 1,
                               prob = c(prob.accident.good.driver,
                                        1 - prob.accident.good.driver) )
    } else {
        accident.status <- sample( c("Accident", "No Accident"), 1,
                               prob = c(prob.accident.bad.driver,
                                        1 - prob.accident.bad.driver) )
    }
    
    # Now we store the driver status and the accident status in result vectors:
    
    driver.vector[ replication.index ] <- driver.status
    accident.vector[ replication.index ] <- accident.status
    
}

# Finally, we use standard filtering method. First, we extract those
# elements of the driver vector that had an accident.

filtered.vector <- driver.vector[ accident.vector == "Accident" ]

# Next, we determine the proportion of the filtered values
# that were bad drivers

mean( filtered.vector == "Bad Driver" )
```
The simulated value should be very close to 0.382.



\newpage
# Problem 4

In this problem, we will perform some simple explorations with the binomial distribution.

Suppose we have a binomial distribution with $n = 8$ trials and a probability of success of $p = 0.35$. 

### Part (a)

The standard probability formula for the binomial distribution is:
$$
\Pr(X = k)\ =\ {n \choose k} \cdot p^k \cdot (1-p)^{n-k}
$$
Using this formula, calculate the probability of observing exactly 4 successes for the binomial distribution specified above.

**Answer**

```{r}
choose(8, 4) * 0.35^4 * (1-0.35)^(8-4)
```





### Part (b)

Using the built-in function `dbinom()`, calculate the probability of observing exactly 4 successes for the binomial distribution specified above.

**Answer**

```{r}
dbinom(4, 8, 0.35)
```
This should be exactly the same value as you calculated in part (a).



### Part (c)

Using the built-in function `pbinom()`, calculate the probability of observing no more than 3 successes for this binomial distribution.

**Answer**

```{r}
pbinom(3, 8, 0.35)
```



### Part (d)

Calculate the expected value and variance of this binomial distribution.

**Answer** The expected value for any binomial distribution is $n \cdot p$:
```{r}
number.trials <- 8
probability.success <- 0.35

binomial.expected.value <- number.trials * probability.success
binomial.variance <- number.trials * probability.success * (1 - probability.success)

cat( "The expected value is:", binomial.expected.value, "\n" )
cat( "The variance is:", binomial.variance, "\n" )
```



### Part (e)

Construct a simulation to verify your answers for parts (a) through (d). In this simulation, you should directly model the concept that a binomial random variable is a sum of Bernoulli random variables. To do this, for each replication of the `for` loop you should use the `sample()` function to generate 8 independent Bernoulli random variables with probability of success $p = 0.35$, and then add them together. Do NOT use the `rbinom()` function to generate the random binomial value, because that's too easy -- instead, really try to capture the idea that the binomial distribution is just a sum of Bernoulli random variables.

**Answer**

```{r}
number.trials <- 8
probability.success <- 0.35

number.replications <- 10000

result.vector <- numeric( number.replications )

for( replication.index in 1:number.replications ) {
    
    random.binomial.value <- sum( sample( c(1, 0),
                                          number.trials,
                                          replace = TRUE,
                                          c(probability.success, 1 - probability.success)))
    
    result.vector[ replication.index ] <- random.binomial.value
}

cat( "Pr(X=4):", mean( result.vector == 4), "\n" )
cat( "Pr(X <= 3):", mean( result.vector <= 3 ),"\n" )
cat( "Expected value:", mean( result.vector), "\n" )
cat( "Variance:", var( result.vector), "\n" )
```

The simulated value for the probability of observing exactly 4 successes should be close to 0.188. The simulated value for the cumulative probability of observing at most 3 success should be close to 0.706. The simulated value for the expectation should be close to 2.8, and the value for the variance should be close to 1.82.



\newpage
# Problem 5

Each day for 3 weeks, the philosopher Z'aph'ma goes to his local convenience store and purchases an 8-spot Massachusetts State Lottery Keno ticket.

### Part (a)

An 8-spot Keno ticket will win some money if at least 4 of the selected numbers match the 20-number sample. What is the probability that an individual 8-spot Keno ticket will win some money i.e.\ have a positive payout? Calculate this value using the `phyper()` function, and store the value in the variable `winning.keno.prob`. Remember that we're only interested in whether or not the ticket wins some money; we don't care about how much the payout is.

**Answer** There are many ways to calculate this winning probability. First, we can use `phyper()` with the `lower.tail = FALSE` option:
```{r}
winning.keno.prob <- phyper( 3, 8, 72, 20, lower.tail = FALSE )
winning.keno.prob
```

We could also use the complement trick for conditional probabilities:
```{r}
1 - phyper(3, 8, 72, 20)
```

Although the problem statement explicitly said to use the `phyper()` function, you could also calculate this cumulative probability using vectorized operations with the `dhyper()` function:
```{r}
sum( dhyper( 4:8, 8, 72, 20) )
```






### Part (b)

What is the probability that Z'aph'ma will have at least 3 winning tickets during the 3-week period that he purchases Keno tickets? Calculate this using the `pbinom()` function and the `winning.keno.prob` value that you calculated in part (a).

**Answer**

This is a binomial probability. The number of trials is 21, because Z'aph'ma buys one ticket each day for 3 weeks. The probability of success in any trial is the value that you calculated in part (a) and stored in the variable `winning.keno.prob`. Finally, we want to determine the probability of winning at least 3 times during the 21 trials i.e. we want to know the probability of obtaining at least 3 success during the 21 trials. Thus we have:
```{r}
pbinom( 2, 21, winning.keno.prob, lower.tail = FALSE )
```






### Part (c)

Construct a simulation to verify your calculation in part (c):

* Start out the usual way, by defining the number of replications and a logical vector to store your simulation results. Then begin a `for` loop, and for each time through, do this:

    * To simulate playing Keno for 3 weeks, use the `rhyper()` function to draw 21 random values from a hypergeometric distribution. Store this random sample in a variable called `random.sample`.

    * Count how many elements in `random.sample` are greater than or equal to 4, and store this value in a variable called `number.winning.tickets`.

    * Test to see if `number.winning.tickets` is greater than or equal to 3, and if it is, store the value `TRUE` in your result vector.

* When the `for` loop is done, calculate the proportion of `TRUE` values in your result vector.


**Answer**

```{r}
number.replications <- 10000

result.vector <- logical( number.replications )

for( replication.index in 1:number.replications ) {
    three.weeks.keno <- rhyper( 21, 8, 72, 20)
    
    number.winning.tickets <- sum( three.weeks.keno >= 4)
    
    if( number.winning.tickets >= 3 ) {
        result.vector[ replication.index ] <- TRUE
    }
}

cat( "Probability of at least 3 winning tickets:", mean( result.vector ) )
```
This value should be very close to 0.3656.




\newpage
# Problem 6

In the game of Chuck-A-Luck, the player places a \$1 wager, selects a number from 1 to 6 and then rolls 3 dice. If the selected number comes up exactly once out of the three dice, the player gets the initial wager back, along with an additional \$1. If the selected number comes up exactly twice out the three dice, then the player gets the initial wager back, along with an additional \$2. Finally, if the selected number comes up on all three of the dice, the player gets the initial wager back, plus an additional \$10.

###Part (a)

Calculate the expected profit for Chuck-A-Luck. Use the `dbinom()` function to calculate the selected number coming up once, twice, or three times on the three dice.

**Answer**

First let's calculate the probabilites of getting 0, 1, 2, or 3 successes in 3 rolls. Do you see that this is a binomial probability?
```{r}
chuck.a.luck.probs <- c( dbinom(0, 3, 1/6), dbinom(1, 3, 1/6), 
                         dbinom(2, 3, 1/6), dbinom(3, 3, 1/6) )
chuck.a.luck.probs
```
If you like vectorized operations, you could have also done this:
```{r}
chuck.a.luck.probs <- dbinom(0:3, 3, 1/6)
chuck.a.luck.probs
```

The profit vector is:
```{r}
chuck.a.luck.profit <- c(-1, 1, 2, 10)
```

The expected value is:
```{r}
sum( chuck.a.luck.probs * chuck.a.luck.profit )
```



###Part (b)

Construct a simulation to verify that your calculation in part (a) of the expected profit was correct. Again, do not use the `rbinom()` function, but instead use `sample()` to directly model the action of rolling three dice.

**Answer**

```{r}
number.replications <- 100000

profit.vector <- numeric( number.replications )

for( replication.index in 1:number.replications ) {
    
    random.three.rolls <- sample( 1:6, 3, replace = TRUE)
    
    chuck.a.luck.score <- sum( random.three.rolls == 1 )

    if( chuck.a.luck.score == 0 ) {
        profit.vector[ replication.index ] <- -1
    } else if (chuck.a.luck.score == 1) {
        profit.vector[ replication.index ] <- 1
    } else if (chuck.a.luck.score == 2) {
        profit.vector[ replication.index ] <- 2
    } else {
        profit.vector[ replication.index ] <- 10
    }
}

mean( profit.vector )
```
This value should be very close to -0.046.






\newpage
# Problem 7

We usually specify a binomial distribution by assigning values to $n$, the number of trials, and $p$, the probability of success. Suppose you don't know either $n$ or $p$, but you do know that the expected value of the distribution is 6, and also that the variance is 1.5:
\begin{eqnarray*}
\hbox{E}[X] & = & 6\\
\\
\hbox{Var}[X] & = & 1.5
\end{eqnarray*}

### Part (a)

Using the values of the expected value and variance, calculate the values of $n$ and $p$. Hint: look in the lecture for the algebraic expressions for the mean and variance of a binomial distribution, and then think about what the algebraic expression is for the variance divided by the mean.

**Answer** We know from lecture that we can write the expected value and variance of a binomial random variable like this:
\begin{eqnarray*}
    \hbox{E}[X] & = & n \cdot p\\
    \\
    \hbox{Var}[X] & = & n \cdot p \cdot (1-p)
\end{eqnarray*}
If we take the hint and divide the variance by the expected value, we have:
\begin{eqnarray*}
    \frac{ \hbox{Var}[X] }{ \hbox{E}[X] } & = & \frac{ np \cdot (1-p) }{np}\\
    \\
    & = & 1-p
\end{eqnarray*}
However, for this problem, the problem statement specifies numerical values for the variance and the expected value, so we have:
\begin{eqnarray*}
    \frac{ \hbox{Var}[X] }{ \hbox{E}[X] } & = & \frac{ 1.5 }{6}\\
    \\
    & = & 0.25
\end{eqnarray*}
Thus we have:
$$
1-p = 0.25
$$
Solving for $p$, we have:
$$
p = 0.75
$$

Now we can solve for $n$. We know that $\hbox{E}[X] = n \cdot p$, so therefore:
\begin{eqnarray*}
    n & = & \frac{ \hbox{E}[X] }{ p }\\
    \\
    & = & \frac{ 6 }{ 0.75 }\\
    \\
    & = & 8
\end{eqnarray*}
Thus, we have solved for the two parameters $n$ and $p$:
\begin{eqnarray*}
    n & = & 8\\
    \\
    p & = & 0.75
\end{eqnarray*}




### Part (b)

Using the values of $n$ and $p$ that you obtained in part (a), conduct a simulation to show that the resulting binomial distribution really does have an expected value of 6 and a variance of 1.5. Once again, don't use the built-in `rbinom()` function to generate random binomial values, but instead use the `sample()` function to generate $n$ independent Bernoulli random variables, each with common probability of success $p$. Once you've finished the simulation, calculate the mean and variance of the `result.vector` and show that they are very close to the values specified in the problem statement.

**Answer**

```{r}
number.replications <- 10000

result.vector <- numeric( number.replications )

number.trials <- 8
probability.success <- 0.75

for( replication.index in 1:number.replications ) {
    
    random.binomial.value <- sum( sample( c(1, 0), number.trials, replace = TRUE,
                                          c(probability.success, 1 - probability.success)))
    
    result.vector[ replication.index ] <- random.binomial.value
}

cat( "Simulated expected value:", mean( result.vector ), "\n" )
cat( "Simulated variance:", var( result.vector ), "\n" )
```
The expected value should be very close to 6, and the variance should be very close to 1.5.


\newpage
# Problem 8

Chicken Curry takes 40 shots, and for each shot he scores a basket with probability $p = 0.42$. Kobe Beef is a total ball hog, and he takes 55 shots, but for each each shot he scores a basket with probability $p = 0.35$. Assume that all the shots are independent of one another. What is the probability that Kobe will score more baskets than Chicken? Answer this by constructing a simulation. You'll have to determine how to model Chicken's number of baskets, as well as Kobe's number of baskets, and then what to do with the results.

**Answer**

```{r}
number.replications <- 10000

result.vector <- logical( number.replications )

for( replication.index in 1:number.replications ) {
    chicken.score <- sum( sample( c(1,0), 40, replace = TRUE, prob = c(0.42, 0.58) ) )
    kobe.score <- sum( sample( c(1,0), 55, replace = TRUE, prob = c(0.35, 0.65) ) )
    
    if( kobe.score > chicken.score ) {
        result.vector[ replication.index ] <- TRUE
    }
}

mean( result.vector )
```





























